{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(r'C:\\Users\\HP\\jigsaw-toxic-comment-classification-challenge\\train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  none  \n",
       "0             0        0       0       0              0     1  \n",
       "1             0        0       0       0              0     1  \n",
       "2             0        0       0       0              0     1  \n",
       "3             0        0       0       0              0     1  \n",
       "4             0        0       0       0              0     1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "train['none'] = 1-train[labels].max(axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey man im really not trying to edit war its just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To lowercase all the text \n",
    "train['comment_text'] = train['comment_text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "# To remove all punctuations and special characters\n",
    "train['comment_text'] = train['comment_text'].str.replace('[^\\w\\s]','')\n",
    "train.loc[2, 'comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey man im trying edit war guy constantly removing relevant information talking edits instead talk page care formatting actual info'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "train['comment_text'] = train['comment_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopwords))\n",
    "train.loc[2, 'comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate', 'none']\n",
    "x = train['comment_text']\n",
    "y = train[labels]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary is: 217942\n",
      "Train Set:  127656\n",
      "Test Set: 31915\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 50000\n",
    "embedding_dim = 32\n",
    "max_length = 240\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = \"<oov>\")\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "print('vocabulary is:', len(tokenizer.word_index))\n",
    "x_train = (tokenizer.texts_to_sequences(x_train))\n",
    "x_test = (tokenizer.texts_to_sequences(x_test))\n",
    "print('Train Set: ', len(x_train))\n",
    "print('Test Set:' , len(x_test))\n",
    "x_train = pad_sequences(x_train, padding = 'post', maxlen=max_length)\n",
    "x_test = pad_sequences(x_test, padding = 'post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 240, 32)           1600000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 240, 32)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               49664     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 1,658,375\n",
      "Trainable params: 1,658,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/30\n",
      "127656/127656 - 5127s - loss: 0.4708 - accuracy: 0.9378 - val_loss: 0.4220 - val_accuracy: 0.9336\n",
      "Epoch 2/30\n",
      "127656/127656 - 1679s - loss: 0.3870 - accuracy: 0.9506 - val_loss: 0.4182 - val_accuracy: 0.9580\n",
      "Epoch 3/30\n",
      "127656/127656 - 1642s - loss: 0.3637 - accuracy: 0.9545 - val_loss: 0.4150 - val_accuracy: 0.9583\n",
      "Epoch 4/30\n",
      "127656/127656 - 1472s - loss: 0.3442 - accuracy: 0.9581 - val_loss: 0.4492 - val_accuracy: 0.9542\n",
      "Epoch 5/30\n",
      "127656/127656 - 1355s - loss: 0.3289 - accuracy: 0.9613 - val_loss: 0.4436 - val_accuracy: 0.9473\n",
      "Epoch 6/30\n",
      "127656/127656 - 1495s - loss: 0.3165 - accuracy: 0.9624 - val_loss: 0.4921 - val_accuracy: 0.9353\n",
      "Epoch 7/30\n",
      "127656/127656 - 1555s - loss: 0.3059 - accuracy: 0.9636 - val_loss: 0.4720 - val_accuracy: 0.9389\n",
      "Epoch 8/30\n",
      "127656/127656 - 1400s - loss: 0.2987 - accuracy: 0.9636 - val_loss: 0.5074 - val_accuracy: 0.9118\n",
      "Epoch 9/30\n",
      "127656/127656 - 1394s - loss: 0.2908 - accuracy: 0.9637 - val_loss: 0.5099 - val_accuracy: 0.9310\n",
      "Epoch 10/30\n",
      "127656/127656 - 1282s - loss: 0.2842 - accuracy: 0.9633 - val_loss: 0.5163 - val_accuracy: 0.9265\n",
      "Epoch 11/30\n",
      "127656/127656 - 1269s - loss: 0.2786 - accuracy: 0.9641 - val_loss: 0.5270 - val_accuracy: 0.9335\n",
      "Epoch 12/30\n",
      "127656/127656 - 1329s - loss: 0.2736 - accuracy: 0.9646 - val_loss: 0.5575 - val_accuracy: 0.9357\n",
      "Epoch 13/30\n",
      "127656/127656 - 1593s - loss: 0.2688 - accuracy: 0.9638 - val_loss: 0.5958 - val_accuracy: 0.9155\n",
      "Epoch 14/30\n",
      "127656/127656 - 1543s - loss: 0.2643 - accuracy: 0.9634 - val_loss: 0.5865 - val_accuracy: 0.9339\n",
      "Epoch 15/30\n",
      "127656/127656 - 1376s - loss: 0.2618 - accuracy: 0.9645 - val_loss: 0.6173 - val_accuracy: 0.9450\n",
      "Epoch 16/30\n",
      "127656/127656 - 1363s - loss: 0.2582 - accuracy: 0.9649 - val_loss: 0.6185 - val_accuracy: 0.9165\n",
      "Epoch 17/30\n",
      "127656/127656 - 1276s - loss: 0.2567 - accuracy: 0.9646 - val_loss: 0.6057 - val_accuracy: 0.9343\n",
      "Epoch 18/30\n",
      "127656/127656 - 1269s - loss: 0.2546 - accuracy: 0.9652 - val_loss: 0.6353 - val_accuracy: 0.9332\n",
      "Epoch 19/30\n",
      "127656/127656 - 1270s - loss: 0.2515 - accuracy: 0.9660 - val_loss: 0.6147 - val_accuracy: 0.9296\n",
      "Epoch 20/30\n",
      "127656/127656 - 1277s - loss: 0.2501 - accuracy: 0.9664 - val_loss: 0.6320 - val_accuracy: 0.9166\n",
      "Epoch 21/30\n",
      "127656/127656 - 1275s - loss: 0.2484 - accuracy: 0.9664 - val_loss: 0.6565 - val_accuracy: 0.9349\n",
      "Epoch 22/30\n",
      "127656/127656 - 1274s - loss: 0.2472 - accuracy: 0.9668 - val_loss: 0.6282 - val_accuracy: 0.9384\n",
      "Epoch 23/30\n",
      "127656/127656 - 1270s - loss: 0.2450 - accuracy: 0.9663 - val_loss: 0.6389 - val_accuracy: 0.9382\n",
      "Epoch 24/30\n",
      "127656/127656 - 1302s - loss: 0.2435 - accuracy: 0.9662 - val_loss: 0.6783 - val_accuracy: 0.9212\n",
      "Epoch 25/30\n",
      "127656/127656 - 1271s - loss: 0.2419 - accuracy: 0.9671 - val_loss: 0.6570 - val_accuracy: 0.9367\n",
      "Epoch 26/30\n",
      "127656/127656 - 1271s - loss: 0.2412 - accuracy: 0.9679 - val_loss: 0.6700 - val_accuracy: 0.9307\n",
      "Epoch 27/30\n",
      "127656/127656 - 1272s - loss: 0.2402 - accuracy: 0.9674 - val_loss: 0.6489 - val_accuracy: 0.9226\n",
      "Epoch 28/30\n",
      "127656/127656 - 1272s - loss: 0.2389 - accuracy: 0.9671 - val_loss: 0.6781 - val_accuracy: 0.9259\n",
      "Epoch 29/30\n",
      "127656/127656 - 1271s - loss: 0.2381 - accuracy: 0.9671 - val_loss: 0.6894 - val_accuracy: 0.9221\n",
      "Epoch 30/30\n",
      "127656/127656 - 1270s - loss: 0.2372 - accuracy: 0.9682 - val_loss: 0.6917 - val_accuracy: 0.9261\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "num_epochs = 30\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, validation_data=(x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 240, 32)           1600000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 240, 32)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 128)               49664     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,667,079\n",
      "Trainable params: 1,667,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/30\n",
      "127656/127656 - 1253s - loss: 0.8660 - accuracy: 0.8987 - val_loss: 0.8463 - val_accuracy: 0.8964\n",
      "Epoch 2/30\n",
      "127656/127656 - 1291s - loss: 0.8260 - accuracy: 0.8988 - val_loss: 0.9014 - val_accuracy: 0.8964\n",
      "Epoch 3/30\n",
      "127656/127656 - 1295s - loss: 0.6775 - accuracy: 0.9119 - val_loss: 0.5544 - val_accuracy: 0.9280\n",
      "Epoch 4/30\n",
      "127656/127656 - 1291s - loss: 0.5256 - accuracy: 0.9320 - val_loss: 0.4894 - val_accuracy: 0.9401\n",
      "Epoch 5/30\n",
      "127656/127656 - 1293s - loss: 0.4768 - accuracy: 0.9385 - val_loss: 0.4726 - val_accuracy: 0.9405\n",
      "Epoch 6/30\n",
      "127656/127656 - 1294s - loss: 0.4445 - accuracy: 0.9441 - val_loss: 0.4463 - val_accuracy: 0.9456\n",
      "Epoch 7/30\n",
      "127656/127656 - 1293s - loss: 0.4302 - accuracy: 0.9470 - val_loss: 0.4407 - val_accuracy: 0.9495\n",
      "Epoch 8/30\n",
      "127656/127656 - 1294s - loss: 0.4510 - accuracy: 0.9448 - val_loss: 0.4646 - val_accuracy: 0.9442\n",
      "Epoch 9/30\n",
      "127656/127656 - 1295s - loss: 0.4307 - accuracy: 0.9466 - val_loss: 0.4335 - val_accuracy: 0.9511\n",
      "Epoch 10/30\n",
      "127656/127656 - 1298s - loss: 0.4184 - accuracy: 0.9483 - val_loss: 0.4617 - val_accuracy: 0.9426\n",
      "Epoch 11/30\n",
      "127656/127656 - 1293s - loss: 0.4074 - accuracy: 0.9518 - val_loss: 0.4268 - val_accuracy: 0.9500\n",
      "Epoch 12/30\n",
      "127656/127656 - 1297s - loss: 0.4008 - accuracy: 0.9527 - val_loss: 0.9641 - val_accuracy: 0.7404\n",
      "Epoch 13/30\n",
      "127656/127656 - 1300s - loss: 0.3960 - accuracy: 0.9536 - val_loss: 0.4236 - val_accuracy: 0.9443\n",
      "Epoch 14/30\n",
      "127656/127656 - 1300s - loss: 0.3919 - accuracy: 0.9540 - val_loss: 0.4238 - val_accuracy: 0.9543\n",
      "Epoch 15/30\n",
      "127656/127656 - 1298s - loss: 0.3922 - accuracy: 0.9543 - val_loss: 0.4383 - val_accuracy: 0.9472\n",
      "Epoch 16/30\n",
      "127656/127656 - 1299s - loss: 0.3867 - accuracy: 0.9564 - val_loss: 0.4294 - val_accuracy: 0.9526\n",
      "Epoch 17/30\n",
      "127656/127656 - 1621s - loss: 0.3888 - accuracy: 0.9558 - val_loss: 0.4212 - val_accuracy: 0.9522\n",
      "Epoch 18/30\n",
      "127656/127656 - 1660s - loss: 0.3815 - accuracy: 0.9572 - val_loss: 0.4297 - val_accuracy: 0.9578\n",
      "Epoch 19/30\n",
      "127656/127656 - 1770s - loss: 0.3791 - accuracy: 0.9571 - val_loss: 0.4242 - val_accuracy: 0.9580\n",
      "Epoch 20/30\n",
      "127656/127656 - 1736s - loss: 0.3756 - accuracy: 0.9580 - val_loss: 0.4252 - val_accuracy: 0.9583\n",
      "Epoch 21/30\n",
      "127656/127656 - 1836s - loss: 0.3743 - accuracy: 0.9583 - val_loss: 0.4233 - val_accuracy: 0.9569\n",
      "Epoch 22/30\n",
      "127656/127656 - 1759s - loss: 0.3719 - accuracy: 0.9597 - val_loss: 0.4374 - val_accuracy: 0.9433\n",
      "Epoch 23/30\n",
      "127656/127656 - 1751s - loss: 0.3728 - accuracy: 0.9592 - val_loss: 0.4390 - val_accuracy: 0.9542\n",
      "Epoch 24/30\n",
      "127656/127656 - 1754s - loss: 0.3703 - accuracy: 0.9584 - val_loss: 0.4332 - val_accuracy: 0.9449\n",
      "Epoch 25/30\n",
      "127656/127656 - 1748s - loss: 0.3663 - accuracy: 0.9607 - val_loss: 0.4327 - val_accuracy: 0.9414\n",
      "Epoch 26/30\n",
      "127656/127656 - 1809s - loss: 0.3659 - accuracy: 0.9609 - val_loss: 0.4208 - val_accuracy: 0.9554\n",
      "Epoch 27/30\n",
      "127656/127656 - 2000s - loss: 0.3650 - accuracy: 0.9612 - val_loss: 0.4416 - val_accuracy: 0.9330\n",
      "Epoch 28/30\n",
      "127656/127656 - 2007s - loss: 0.3630 - accuracy: 0.9613 - val_loss: 0.4373 - val_accuracy: 0.9538\n",
      "Epoch 29/30\n",
      "127656/127656 - 1991s - loss: 0.3737 - accuracy: 0.9602 - val_loss: 0.5349 - val_accuracy: 0.9404\n",
      "Epoch 30/30\n",
      "127656/127656 - 1994s - loss: 0.3940 - accuracy: 0.9596 - val_loss: 0.4344 - val_accuracy: 0.9546\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "num_epochs = 30\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, validation_data=(x_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv(r'C:\\Users\\HP\\jigsaw-toxic-comment-classification-challenge\\test.csv')\n",
    "test_labels = pd.read_csv(r'C:\\Users\\HP\\jigsaw-toxic-comment-classification-challenge\\test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "5   0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
       "7   000247e83dcc1211                   :Dear god this site is horrible.   \n",
       "11  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...   \n",
       "13  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...   \n",
       "14  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...   \n",
       "\n",
       "                  id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "5   0001ea8717f6de06      0             0        0       0       0   \n",
       "7   000247e83dcc1211      0             0        0       0       0   \n",
       "11  0002f87b16116a7f      0             0        0       0       0   \n",
       "13  0003e1cccfd5a40a      0             0        0       0       0   \n",
       "14  00059ace3e3e9a53      0             0        0       0       0   \n",
       "\n",
       "    identity_hate  \n",
       "5               0  \n",
       "7               0  \n",
       "11              0  \n",
       "13              0  \n",
       "14              0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatination of Test Features and Test Labels\n",
    "test = pd.concat([test_features, test_labels], axis = 1)\n",
    "\n",
    "# Removal of data points which were incorrectly labeled\n",
    "columns = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "for column in columns:\n",
    "    test = test.drop(test[test[column] == -1 ].index, axis = 0)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>thank understanding think highly revert discus...</td>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>dear god site horrible</td>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>somebody invariably try add religion mean way ...</td>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>says right type type institution needed case l...</td>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>adding new product list sure relevant adding n...</td>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "5   0001ea8717f6de06  thank understanding think highly revert discus...   \n",
       "7   000247e83dcc1211                             dear god site horrible   \n",
       "11  0002f87b16116a7f  somebody invariably try add religion mean way ...   \n",
       "13  0003e1cccfd5a40a  says right type type institution needed case l...   \n",
       "14  00059ace3e3e9a53  adding new product list sure relevant adding n...   \n",
       "\n",
       "                  id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "5   0001ea8717f6de06      0             0        0       0       0   \n",
       "7   000247e83dcc1211      0             0        0       0       0   \n",
       "11  0002f87b16116a7f      0             0        0       0       0   \n",
       "13  0003e1cccfd5a40a      0             0        0       0       0   \n",
       "14  00059ace3e3e9a53      0             0        0       0       0   \n",
       "\n",
       "    identity_hate  none  \n",
       "5               0     1  \n",
       "7               0     1  \n",
       "11              0     1  \n",
       "13              0     1  \n",
       "14              0     1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['comment_text'] = test['comment_text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test['comment_text'] = test['comment_text'].str.replace('[^\\w\\s]','')\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "test['comment_text'] = test['comment_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopwords))\n",
    "# Adding adition category for such comments that do no belong to any categories in the data\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "test['none'] = 1-train[labels].max(axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63978, 240), (63978, 7))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate', 'none']\n",
    "x_test = test['comment_text']\n",
    "y_test = test[labels]\n",
    "\n",
    "x_test = (tokenizer.texts_to_sequences(x_test))\n",
    "x_test = pad_sequences(x_test, padding = 'post', maxlen=max_length)\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63978/63978 - 269s - loss: 0.9248 - accuracy: 0.8360\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size= 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
